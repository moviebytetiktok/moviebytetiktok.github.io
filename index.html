<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Video Subtitle Generator</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="https://unpkg.com/vosk@0.3.45/vosk.js"></script>
</head>
<body class="bg-gray-100 flex flex-col items-center justify-center min-h-screen">
  <div class="bg-white p-6 rounded-lg shadow-lg w-full max-w-2xl">
    <h1 class="text-2xl font-bold mb-4 text-center">Video Subtitle Generator</h1>
    <input type="file" id="videoInput" accept="video/*" class="mb-4 w-full p-2 border rounded">
    <video id="videoPlayer" controls class="w-full mb-4" style="display: none;"></video>
    <button id="processButton" class="bg-blue-500 text-white px-4 py-2 rounded w-full hover:bg-blue-600" disabled>Process Video</button>
    <p id="status" class="mt-4 text-center"></p>
  </div>

  <script>
    const videoInput = document.getElementById('videoInput');
    const videoPlayer = document.getElementById('videoPlayer');
    const processButton = document.getElementById('processButton');
    const status = document.getElementById('status');

    let model;
    let subtitles = [];
    let isProcessing = false;

    // Load Vosk model
    async function loadModel() {
      status.textContent = 'Loading speech recognition model...';
      try {
        model = await Vosk.createModel('https://github.com/alphacep/vosk-model-small-en-us/releases/download/v0.15/vosk-model-small-en-us-0.15.zip');
        status.textContent = 'Model loaded. Upload a video to proceed.';
      } catch (error) {
        status.textContent = `Error loading model: ${error.message}`;
        processButton.disabled = true;
      }
    }

    loadModel();

    // Enable process button when video is selected
    videoInput.addEventListener('change', (event) => {
      const file = event.target.files[0];
      if (file) {
        const url = URL.createObjectURL(file);
        videoPlayer.src = url;
        videoPlayer.style.display = 'block';
        processButton.disabled = !model;
        status.textContent = 'Video loaded. Click "Process Video" to generate subtitles.';
      }
    });

    // Process video for subtitles
    processButton.addEventListener('click', async () => {
      if (isProcessing || !model) return;
      isProcessing = true;
      processButton.disabled = true;
      status.textContent = 'Processing audio for subtitles...';

      subtitles = [];
      const track = videoPlayer.textTracks[0] || videoPlayer.addTextTrack('subtitles', 'English', 'en');
      track.mode = 'showing';

      try {
        // Extract audio from video
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const videoFile = videoInput.files[0];
        const arrayBuffer = await videoFile.arrayBuffer();
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

        // Convert audio buffer to WAV format for Vosk
        const wavBuffer = audioBufferToWav(audioBuffer);
        const recognizer = new model.Recognizer({ sampleRate: audioBuffer.sampleRate });

        // Process audio in chunks
        const chunkSize = 1024 * 1024; // 1MB chunks
        let offset = 0;
        let currentTime = 0;
        while (offset < wavBuffer.length) {
          const chunk = wavBuffer.slice(offset, offset + chunkSize);
          recognizer.acceptWaveform(chunk);
          const result = recognizer.result();
          if (result.text) {
            const startTime = currentTime;
            const endTime = currentTime + 2; // Approximate duration per subtitle
            subtitles.push({ start: startTime, end: endTime, text: result.text });
            addSubtitleToTrack(track, startTime, endTime, result.text);
            currentTime += 2;
          }
          offset += chunkSize;
        }

        recognizer.finalize();
        status.textContent = 'Subtitles generated successfully!';
        generateVTTFile();
      } catch (error) {
        status.textContent = `Error processing audio: ${error.message}`;
      } finally {
        isProcessing = false;
        processButton.disabled = false;
        audioContext.close();
      }
    });

    // Add subtitle to text track
    function addSubtitleToTrack(track, start, end, text) {
      track.addCue(new VTTCue(start, end, text));
    }

    // Generate and download VTT file
    function generateVTTFile() {
      let vttContent = 'WEBVTT\n\n';
      subtitles.forEach(sub => {
        const start = formatTime(sub.start);
        const end = formatTime(sub.end);
        vttContent += `${start} --> ${end}\n${sub.text}\n\n`;
      });

      const blob = new Blob([vttContent], { type: 'text/vtt' });
      const url = URL.createObjectURL(blob);
      const existingTrack = videoPlayer.querySelector('track');
      if (existingTrack) {
        existingTrack.src = url;
      } else {
        const trackElement = document.createElement('track');
        trackElement.kind = 'subtitles';
        trackElement.label = 'English';
        trackElement.srclang = 'en';
        trackElement.src = url;
        trackElement.default = true;
        videoPlayer.appendChild(trackElement);
      }
    }

    // Format time for VTT (e.g., 00:00:00.000)
    function formatTime(seconds) {
      const hours = Math.floor(seconds / 3600);
      const minutes = Math.floor((seconds % 3600) / 60);
      const secs = Math.floor(seconds % 60);
      const millis = Math.floor((seconds % 1) * 1000);
      return `${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}.${millis.toString().padStart(3, '0')}`;
    }

    // Convert AudioBuffer to WAV (simplified, assumes mono for compatibility)
    function audioBufferToWav(buffer) {
      const numChannels = buffer.numberOfChannels;
      const sampleRate = buffer.sampleRate;
      const length = buffer.length * numChannels * 2 + 44;
      const arrayBuffer = new ArrayBuffer(length);
      const view = new DataView(arrayBuffer);

      // Write WAV header
      writeString(view, 0, 'RIFF');
      view.setUint32(4, length - 8, true);
      writeString(view, 8, 'WAVE');
      writeString(view, 12, 'fmt ');
      view.setUint32(16, 16, true);
      view.setUint16(20, 1, true); // PCM format
      view.setUint16(22, numChannels, true);
      view.setUint32(24, sampleRate, true);
      view.setUint32(28, sampleRate * numChannels * 2, true);
      view.setUint16(32, numChannels * 2, true);
      view.setUint16(34, 16, true);
      writeString(view, 36, 'data');
      view.setUint32(40, buffer.length * numChannels * 2, true);

      // Write PCM data
      const channelData = buffer.getChannelData(0); // Use first channel for simplicity
      for (let i = 0; i < buffer.length; i++) {
        view.setInt16(44 + i * 2, channelData[i] * 0x7FFF, true);
      }

      return arrayBuffer;
    }

    function writeString(view, offset, string) {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    }
  </script>
</body>
</html>
